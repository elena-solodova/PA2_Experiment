{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a13c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9df63c",
   "metadata": {},
   "source": [
    "# Einlesen der Daten \n",
    "\n",
    "In diesem Abschnitt werden die Hilfsfunktionen zu Laden der der FastSurfer-Analyseergebnisse definiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ccd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats_file(stats_path):\n",
    "    regions = {}\n",
    "    with open(stats_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                region = parts[4] \n",
    "                try:\n",
    "                    volume = float(parts[3])  \n",
    "                    regions[region] = volume\n",
    "                except ValueError:\n",
    "                    pass \n",
    "    return regions\n",
    "\n",
    "\n",
    "def load_group(base_dir, label):\n",
    "    subjects_data = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file == \"aseg+DKT.stats\":\n",
    "                stats_path = os.path.join(root, file)\n",
    "                # extrahiere Probanden-ID\n",
    "                match = re.search(r'(\\d{3}_S_\\d{4})', stats_path)\n",
    "                subject_id = match.group(1) if match else os.path.basename(root)\n",
    "                \n",
    "                # Lade Gehirnregionen-Volumina für diesen Probanden\n",
    "                regions = read_stats_file(stats_path)\n",
    "                regions[\"subject_id\"] = subject_id\n",
    "                regions[\"Label\"] = label  # AD oder CN\n",
    "                subjects_data.append(regions)\n",
    "    \n",
    "    df = pd.DataFrame(subjects_data)\n",
    "    return df.set_index(\"subject_id\").sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019a6d3",
   "metadata": {},
   "source": [
    "# Lokales SVM-Modell Training mit PyTorch\n",
    "\n",
    "Zuerst wird das Modell lokal trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Hinge Loss\n",
    "def hinge_loss(outputs, labels, C=1.0):\n",
    "    # Labels müssen -1 oder +1 für SVM sein\n",
    "    labels = 2 * labels - 1  \n",
    "    # Standard Hinge Loss kalkulation\n",
    "    loss = torch.mean(torch.clamp(1 - labels * outputs, min=0))\n",
    "    \n",
    "    # globaler Zugriff auf 'model' für L2-Regularisierungsterm \n",
    "    global model \n",
    "    l2_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            l2_reg = l2_reg + torch.norm(param, 2)**2\n",
    "\n",
    "    # Der Faktor (1 / (2 * C)) wird in der primalen SVM-Formulierung verwendet\n",
    "    return loss + (1 / (2 * C)) * l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545aedc",
   "metadata": {},
   "source": [
    "## Laden der Daten\n",
    "Nun werden die Daten geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_dir = \"/Users/hpe/Desktop/MRI/PA2/fast_surfer/AD\" \n",
    "cn_dir = \"/Users/hpe/Desktop/MRI/PA2/fast_surfer/CN\"\n",
    "\n",
    "df_AD = load_group(ad_dir, \"AD\")\n",
    "df_CN = load_group(cn_dir, \"CN\")\n",
    "\n",
    "df_all = pd.concat([df_AD, df_CN])\n",
    "\n",
    "# entfernt Label-Spalten und ersetzt NaNs durch 0\n",
    "X = df_all.drop(columns=[\"Label\"]).fillna(0) \n",
    "# Umwandlung der Labels in binäre Werte\n",
    "y = df_all[\"Label\"].map({\"AD\": 1, \"CN\": 0})\n",
    "\n",
    "# entfernt 0 Spalten\n",
    "X = X.loc[:, (X != 0).any(axis=0)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9c90b",
   "metadata": {},
   "source": [
    "## Aufteilung und Normalisierung \n",
    "In diesem Abschnitt werden die Daten in Trainings- und Testmenge aufgeteilt und normalisiert, um sie für das Modell vorzubereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierung\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Aufteilung in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Konvertiere Daten zu PyTorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Erstelle DataLoader für Trainingsdaten\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f8003",
   "metadata": {},
   "source": [
    "## Training mit Loss-Tracking\n",
    "Ds SVM-Modell wird über mehrere Epochen mit den Trainingsdaten trainiert, wobei nach jeder Epoche der durchschnittliche Verlust (Loss) und die Genauigkeit (Accuracy) für Training und Test berechnet und gespeichert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "36337d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM mit detailliertem Tracking...\n",
      "Input Dimension: 95\n",
      "Training Samples: 17, Test Samples: 8\n",
      "C Parameter: 1.0\n",
      "\n",
      "Epoch [20/100] - Loss: 0.2497, Train Acc: 0.941, Test Acc: 0.500\n",
      "Epoch [40/100] - Loss: 0.1819, Train Acc: 0.941, Test Acc: 0.500\n",
      "Epoch [60/100] - Loss: 0.1726, Train Acc: 1.000, Test Acc: 0.500\n",
      "Epoch [80/100] - Loss: 0.1668, Train Acc: 1.000, Test Acc: 0.500\n",
      "Epoch [100/100] - Loss: 0.2655, Train Acc: 1.000, Test Acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Erweitertes Training mit Loss- und Accuracy-Tracking\n",
    "input_dim = X.shape[1]\n",
    "model_tracked = LinearSVM(input_dim)\n",
    "optimizer_tracked = optim.SGD(model_tracked.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "\n",
    "# Tracking-Listen\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0\n",
    "epochs = 100\n",
    "\n",
    "# Update global model reference for hinge_loss\n",
    "model = model_tracked\n",
    "\n",
    "print(\"Training Linear SVM mit detailliertem Tracking...\")\n",
    "print(f\"Input Dimension: {input_dim}\")\n",
    "print(f\"Training Samples: {len(X_train)}, Test Samples: {len(X_test)}\")\n",
    "print(f\"C Parameter: {C}\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_tracked.train()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer_tracked.zero_grad()\n",
    "        outputs = model_tracked(inputs)\n",
    "        loss = hinge_loss(outputs, labels, C=C)\n",
    "        loss.backward()\n",
    "        optimizer_tracked.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    # Durchschnittlicher Loss für diese Epoche\n",
    "    avg_epoch_loss = np.mean(epoch_losses)\n",
    "    training_losses.append(avg_epoch_loss)\n",
    "    \n",
    "    # Training Accuracy berechnen\n",
    "    model_tracked.eval()\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model_tracked(X_train_tensor)\n",
    "        train_preds = (train_outputs > 0).float()\n",
    "        train_acc = accuracy_score(y_train_tensor, train_preds)\n",
    "        training_accuracies.append(train_acc)\n",
    "        \n",
    "        # Validation Accuracy auf Test Set\n",
    "        test_outputs = model_tracked(X_test_tensor)\n",
    "        test_preds = (test_outputs > 0).float()\n",
    "        test_acc = accuracy_score(y_test_tensor, test_preds)\n",
    "        validation_accuracies.append(test_acc)\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_epoch_loss:.4f}, Train Acc: {train_acc:.3f}, Test Acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cffa90",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Nun werden die beiden Modelle – das zentral trainierte SVM-Modell und das Modell, das im Rahmen des Swarm-Learning-Prozesses entstanden ist – auf denselben Testdaten evaluiert. Dadurch kann die Leistung beider Ansätze direkt miteinander verglichen werden, wobei die Modelle nach ihrem jeweiligen Training gespeichert und anschließend identisch getestet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc9c48",
   "metadata": {},
   "source": [
    "## Lokales SVM-Modell\n",
    "Zunächst erfolgt die Evaluation des lokal trainierten Modells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdb42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LOCAL SVM MODEL - TEST EVALUATION\n",
      "==================================================\n",
      "Test Accuracy: 0.500\n",
      "Precision: 0.667\n",
      "Sensitivity (Recall): 0.400\n",
      "F1-Score: 0.500\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.40      0.67      0.50         3\n",
      "          AD       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.53      0.53      0.50         8\n",
      "weighted avg       0.57      0.50      0.50         8\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "         Predicted\n",
      "         CN  AD\n",
      "Actual CN   2   1\n",
      "       AD   3   2\n",
      "\n",
      "==================================================\n",
      "Modellgewichte erfolgreich gespeichert unter: /Users/hpe/Desktop/MRI/PA2/model/linear_svm_brain_volumes.pt\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Vorhersagen auf Testdaten\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    # Für SVM: Vorhersage basiert auf dem Vorzeichen (> 0 = Klasse 1, <= 0 = Klasse 0)\n",
    "    preds_class = (test_outputs > 0).float()\n",
    "    \n",
    "    # Konvertierung zu numpy für sklearn metrics\n",
    "    y_true = y_test_tensor.squeeze().numpy()\n",
    "    local_pred = preds_class.squeeze().numpy()\n",
    "\n",
    "    # Berechnung aller Metriken für Local Model\n",
    "    local_accuracy = accuracy_score(y_true, local_pred)\n",
    "    local_precision = precision_score(y_true, local_pred)\n",
    "    local_recall = recall_score(y_true, local_pred)  # Sensitivity\n",
    "    local_f1 = f1_score(y_true, local_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"LOCAL SVM MODEL - TEST EVALUATION\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Test Accuracy: {local_accuracy:.3f}\")\n",
    "    print(f\"Precision: {local_precision:.3f}\")\n",
    "    print(f\"Sensitivity (Recall): {local_recall:.3f}\")\n",
    "    print(f\"F1-Score: {local_f1:.3f}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # Detaillierter Klassifikationsbericht\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_true, \n",
    "        local_pred, \n",
    "        target_names=['CN', 'AD']\n",
    "    ))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    local_cm = confusion_matrix(y_true, local_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"         Predicted\")\n",
    "    print(\"         CN  AD\")\n",
    "    print(f\"Actual CN {local_cm[0,0]:3d} {local_cm[0,1]:3d}\")\n",
    "    print(f\"       AD {local_cm[1,0]:3d} {local_cm[1,1]:3d}\")\n",
    "\n",
    "# Speichern des Modells\n",
    "MODEL_DIR = \"/Users/hpe/Desktop/MRI/PA2/models\"\n",
    "MODEL_FILENAME = \"linear_svm_brain_volumes.pt\"\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Modellgewichte erfolgreich gespeichert unter: {MODEL_SAVE_PATH}\")\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909953f5",
   "metadata": {},
   "source": [
    "## Swarm Learning SVM-Modell\n",
    "Das aus dem Swarm-Learning-Prozess stammende Modell wird nun auf denselben Testdaten wie das lokale Modell evaluiert. Das Modell wurde zuvor nach dem Training aus dem Swarm-Learning-System heruntergeladen und steht jetzt für den direkten Leistungsvergleich bereit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5bff7",
   "metadata": {},
   "source": [
    "### Laden von Modell aus SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9606c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture: <class '__main__.LinearSVM'>\n",
      "Input Dimension: 100\n",
      "Output Dimension: 1\n",
      "Total Parameters: 101\n",
      "AKTUELLE DATEN-DIMENSIONEN:\n",
      "========================================\n",
      "X.shape: (25, 95)\n",
      "X_scaled.shape: (25, 95)\n",
      "X_train.shape: (17, 95)\n",
      "X_test.shape: (8, 95)\n",
      "X_test_tensor.shape: torch.Size([8, 95])\n",
      "input_dim (current): 95\n",
      "Anzahl Features: 95\n"
     ]
    }
   ],
   "source": [
    "SWARM_MODEL_PATH = \"/Users/hpe/Desktop/MRI/PA2/models/AD_model_swarm.pth\"\n",
    "swarm_model = torch.load(SWARM_MODEL_PATH, map_location='cpu', weights_only=False)\n",
    "swarm_model.eval()\n",
    "\n",
    "print(f\"Model Architecture: {type(swarm_model)}\")\n",
    "print(f\"Input Dimension: {swarm_model.linear.in_features}\")\n",
    "print(f\"Output Dimension: {swarm_model.linear.out_features}\")\n",
    "\n",
    "# Zeige Modell-Parameter\n",
    "total_params = sum(p.numel() for p in swarm_model.parameters())\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "# Dimensionen der aktuellen Daten überprüfen\n",
    "print(f\"AKTUELLE DATEN-DIMENSIONEN:\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"X_scaled.shape: {X_scaled.shape}\")\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"X_test_tensor.shape: {X_test_tensor.shape}\")\n",
    "print(f\"input_dim (current): {input_dim}\")\n",
    "print(f\"Anzahl Features: {len(X.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74695d9d",
   "metadata": {},
   "source": [
    "### Evaluierung von SL-Modell auf den gleichen Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce92f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SWARM MODEL - TEST EVALUATION\n",
      "==================================================\n",
      "Testdaten von 95 auf 100 Features erweitert (mit 5 Nullen)\n",
      "Swarm Model Input Shape: torch.Size([8, 100])\n",
      "Test Accuracy: 0.875\n",
      "Precision: 0.833\n",
      "Sensitivity (Recall): 1.000\n",
      "F1-Score: 0.909\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       1.00      0.67      0.80         3\n",
      "          AD       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.83      0.85         8\n",
      "weighted avg       0.90      0.88      0.87         8\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "         Predicted\n",
      "         CN  AD\n",
      "Actual CN   2   1\n",
      "       AD   0   5\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SWARM MODEL - TEST EVALUATION\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Erstelle angepasste Testdaten mit Null-Padding für das Swarm-Modell\n",
    "swarm_input_dim = swarm_model.linear.in_features\n",
    "current_dim = X_test_tensor.shape[1]\n",
    "\n",
    "# Dimensionen anpassen\n",
    "if current_dim < swarm_input_dim:\n",
    "    additional_features = swarm_input_dim - current_dim\n",
    "    X_test_swarm = torch.cat([\n",
    "        X_test_tensor, \n",
    "        torch.zeros(X_test_tensor.shape[0], additional_features)\n",
    "    ], dim=1)\n",
    "    print(f\"Testdaten von {current_dim} auf {swarm_input_dim} Features erweitert (mit {additional_features} Nullen)\")\n",
    "else:\n",
    "    X_test_swarm = X_test_tensor[:, :swarm_input_dim]\n",
    "    print(f\"Testdaten von {current_dim} auf {swarm_input_dim} Features reduziert\")\n",
    "\n",
    "print(f\"Swarm Model Input Shape: {X_test_swarm.shape}\")\n",
    "\n",
    "# Testen des Swarm-Modells\n",
    "swarm_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Vorhersagen auf den angepassten Testdaten\n",
    "    swarm_test_outputs = swarm_model(X_test_swarm)\n",
    "    # Für SVM: Vorhersage basiert auf Vorzeichen (> 0 = Klasse 1, <= 0 = Klasse 0)\n",
    "    swarm_preds_class = (swarm_test_outputs > 0).float()\n",
    "\n",
    "    # Konvertierung zu numpy für sklearn metrics\n",
    "    y_true = y_test_tensor.squeeze().numpy()\n",
    "    swarm_pred = swarm_preds_class.squeeze().numpy()\n",
    "\n",
    "    # Berechnung aller Metriken für Swarm Model\n",
    "    swarm_accuracy = accuracy_score(y_true, swarm_pred)\n",
    "    swarm_precision = precision_score(y_true, swarm_pred)\n",
    "    swarm_recall = recall_score(y_true, swarm_pred)  \n",
    "    swarm_f1 = f1_score(y_true, swarm_pred)\n",
    "    \n",
    "    print(f\"Test Accuracy: {swarm_accuracy:.3f}\")\n",
    "    print(f\"Precision: {swarm_precision:.3f}\")\n",
    "    print(f\"Sensitivity (Recall): {swarm_recall:.3f}\")\n",
    "    print(f\"F1-Score: {swarm_f1:.3f}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # Detaillierter Klassifikationsbericht\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_true, \n",
    "        swarm_pred, \n",
    "        target_names=['CN', 'AD']\n",
    "    ))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    swarm_cm = confusion_matrix(y_true, swarm_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"         Predicted\")\n",
    "    print(\"         CN  AD\")\n",
    "    print(f\"Actual CN {swarm_cm[0,0]:3d} {swarm_cm[0,1]:3d}\")\n",
    "    print(f\"       AD {swarm_cm[1,0]:3d} {swarm_cm[1,1]:3d}\")\n",
    "    print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8057894b",
   "metadata": {},
   "source": [
    "## Vergleich der Ergebnisse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec135df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON: LOCAL SVM vs. SWARM MODEL\n",
      "======================================================================\n",
      "\n",
      "METRICS COMPARISON:\n",
      "----------------------------------------------------------------------\n",
      "Metric                    Local SVM    Swarm Model  Difference  \n",
      "----------------------------------------------------------------------\n",
      "Accuracy                  0.500        0.875        +0.375      \n",
      "Precision                 0.667        0.833        +0.167      \n",
      "Sensitivity (Recall)      0.400        1.000        +0.600      \n",
      "F1-Score                  0.500        0.909        +0.409      \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "==================================================\n",
      "CONFUSION MATRICES COMPARISON\n",
      "==================================================\n",
      "\n",
      "Local SVM:\n",
      "         Predicted\n",
      "         CN  AD\n",
      "Actual CN   2   1\n",
      "       AD   3   2\n",
      "\n",
      "Swarm Model:\n",
      "         Predicted\n",
      "         CN  AD\n",
      "Actual CN   2   1\n",
      "       AD   0   5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARISON: LOCAL SVM vs. SWARM MODEL\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Erstelle DataFrame für den Vergleich\n",
    "comparison_metrics = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Sensitivity (Recall)', 'F1-Score'],\n",
    "    'Local SVM': [local_accuracy, local_precision, local_recall, local_f1],\n",
    "    'Swarm Model': [swarm_accuracy, swarm_precision, swarm_recall, swarm_f1]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_metrics)\n",
    "\n",
    "# Berechne Differenzen\n",
    "comparison_df['Difference (Swarm - Local)'] = comparison_df['Swarm Model'] - comparison_df['Local SVM']\n",
    "\n",
    "print(\"METRICS COMPARISON:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Metric':<25} {'Local SVM':<12} {'Swarm Model':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    metric = row['Metric']\n",
    "    local_val = row['Local SVM']\n",
    "    swarm_val = row['Swarm Model'] \n",
    "    diff = row['Difference (Swarm - Local)']\n",
    "    \n",
    "    print(f\"{metric:<25} {local_val:<12.3f} {swarm_val:<12.3f} {diff:<+12.3f}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Detaillierte Confusion Matrix Vergleiche\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CONFUSION MATRICES COMPARISON\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "print(\"\\nLocal SVM:\")\n",
    "print(\"         Predicted\")\n",
    "print(\"         CN  AD\")\n",
    "print(f\"Actual CN {local_cm[0,0]:3d} {local_cm[0,1]:3d}\")\n",
    "print(f\"       AD {local_cm[1,0]:3d} {local_cm[1,1]:3d}\")\n",
    "\n",
    "print(\"\\nSwarm Model:\")\n",
    "print(\"         Predicted\") \n",
    "print(\"         CN  AD\")\n",
    "print(f\"Actual CN {swarm_cm[0,0]:3d} {swarm_cm[0,1]:3d}\")\n",
    "print(f\"       AD {swarm_cm[1,0]:3d} {swarm_cm[1,1]:3d}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
